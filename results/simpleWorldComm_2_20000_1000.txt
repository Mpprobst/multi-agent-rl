Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -27.426120247553236, agent episode reward: [0.8465446031152838, 0.8396132496671516, 0.8276451022171104, 0.8191887804575257, -14.95976890529964, -15.799343077710674], time: 89.279
steps: 49975, episodes: 2000, mean episode reward: 2.5681709072342023, agent episode reward: [2.9403681159123973, 2.7846395340499495, 2.9245420694635302, 3.1564733778483625, -4.378369860827057, -4.85948232921298], time: 146.454
steps: 74975, episodes: 3000, mean episode reward: 14.533559867465987, agent episode reward: [5.112420258357154, 4.461269962508353, 4.813558703314762, 4.810913914880495, -2.2252080048350433, -2.4393949667597337], time: 148.232
steps: 99975, episodes: 4000, mean episode reward: 15.890773808950554, agent episode reward: [5.678461043698792, 5.276865291666214, 5.143909343424253, 5.090031716590983, -2.6524791489561803, -2.6460144374735055], time: 147.911
steps: 124975, episodes: 5000, mean episode reward: 21.360071711945682, agent episode reward: [7.230972007248295, 7.302022605350066, 7.1965716500716175, 6.746146779196512, -4.084151893068566, -3.031489436852246], time: 151.76
steps: 149975, episodes: 6000, mean episode reward: 26.95851203723889, agent episode reward: [8.977222125408138, 9.002563496195869, 8.910738453842063, 8.657568520216348, -4.531151411632452, -4.0584291467910765], time: 148.482
steps: 174975, episodes: 7000, mean episode reward: 28.200214323876548, agent episode reward: [9.379360958646112, 9.230369073237794, 9.324721244220255, 9.262783905067103, -5.388612606704185, -3.608408250590534], time: 151.959
steps: 199975, episodes: 8000, mean episode reward: 27.97558682276716, agent episode reward: [9.41022486930541, 9.180342151930454, 9.338040809884939, 9.350377106407853, -4.740308779152812, -4.563089335608681], time: 145.601
steps: 224975, episodes: 9000, mean episode reward: 24.44410414002777, agent episode reward: [8.545298890970122, 8.29032702676703, 8.43085250922293, 8.501519085414962, -4.730245394253667, -4.5936479780936095], time: 146.665
steps: 249975, episodes: 10000, mean episode reward: 23.77028093591021, agent episode reward: [8.244233920237312, 7.982959736980503, 8.191235659848209, 8.223261051948239, -3.680356220870497, -5.191053212233554], time: 149.187
steps: 274975, episodes: 11000, mean episode reward: 20.26696160359274, agent episode reward: [7.351818776329693, 7.133066926831512, 7.271021867377444, 7.365036525321029, -3.5171167692127994, -5.336865723054138], time: 151.568
steps: 299975, episodes: 12000, mean episode reward: 22.300827024266, agent episode reward: [7.830146722296302, 7.665189738128313, 7.736477092402287, 7.825956256639969, -3.5595002379370886, -5.197442547263783], time: 152.956
steps: 324975, episodes: 13000, mean episode reward: 18.740263953281616, agent episode reward: [6.490936548981389, 6.3170568538825735, 6.296404239855863, 6.422375289439159, -2.726310209290864, -4.060198769586503], time: 155.008
steps: 349975, episodes: 14000, mean episode reward: 18.257774422906316, agent episode reward: [6.334081763460982, 6.1143291524302095, 6.114063741721102, 6.201678324890744, -2.576391672371405, -3.9299868872253128], time: 154.406
steps: 374975, episodes: 15000, mean episode reward: 18.940747528381923, agent episode reward: [6.523919371583121, 6.261206931372164, 6.295862832626879, 6.3269729610707905, -2.4971376869399156, -3.9700768813311176], time: 151.183
steps: 399975, episodes: 16000, mean episode reward: 17.263339687791756, agent episode reward: [5.988208896740361, 5.789447667974359, 5.774034084353876, 5.774294292896192, -2.3439932671915504, -3.718651986981483], time: 155.002
steps: 424975, episodes: 17000, mean episode reward: 18.46454328897975, agent episode reward: [6.323765596331856, 6.13872190340859, 6.103018577609464, 6.134109641837743, -2.0007316504218515, -4.234340779786052], time: 152.264
steps: 449975, episodes: 18000, mean episode reward: 17.930082458166797, agent episode reward: [6.197138392960835, 6.062505562173712, 5.969584582572345, 5.968355859834975, -2.5098272189732818, -3.757674720401788], time: 150.99
steps: 474975, episodes: 19000, mean episode reward: 19.713994818544517, agent episode reward: [6.888904976003718, 6.741816895128204, 6.693627020054035, 6.744888768445552, -2.953194530871018, -4.402048310215973], time: 153.134
steps: 499975, episodes: 20000, mean episode reward: 16.151246914106515, agent episode reward: [5.546417943149514, 5.417697613270031, 5.39863168398756, 5.385657073477659, -2.4144089284147747, -3.182748471363477], time: 152.808
