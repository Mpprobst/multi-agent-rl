Using good policy maddpg and adv policy maddpg
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -37.11683314197539, time: 6.924
steps: 49975, episodes: 2000, mean episode reward: -18.21783740238604, time: 11.921
steps: 74975, episodes: 3000, mean episode reward: -6.317604470653138, time: 11.874
steps: 99975, episodes: 4000, mean episode reward: -5.7868359453051905, time: 11.643
steps: 124975, episodes: 5000, mean episode reward: -6.082921663231668, time: 11.813
steps: 149975, episodes: 6000, mean episode reward: -6.309266554117122, time: 11.847
steps: 174975, episodes: 7000, mean episode reward: -6.127808247499544, time: 11.601
steps: 199975, episodes: 8000, mean episode reward: -5.946141329159874, time: 11.812
steps: 224975, episodes: 9000, mean episode reward: -6.133644182814206, time: 12.206
steps: 249975, episodes: 10000, mean episode reward: -6.249522397642125, time: 11.61
steps: 274975, episodes: 11000, mean episode reward: -5.746254022266169, time: 11.876
steps: 299975, episodes: 12000, mean episode reward: -6.195422034796997, time: 12.048
steps: 324975, episodes: 13000, mean episode reward: -5.961022378282775, time: 11.988
steps: 349975, episodes: 14000, mean episode reward: -6.662226010223294, time: 11.672
steps: 374975, episodes: 15000, mean episode reward: -6.512555946910884, time: 11.864
steps: 399975, episodes: 16000, mean episode reward: -6.6757517742342625, time: 10.998
steps: 424975, episodes: 17000, mean episode reward: -5.863533876373442, time: 11.679
steps: 449975, episodes: 18000, mean episode reward: -6.471659414970985, time: 11.452
steps: 474975, episodes: 19000, mean episode reward: -6.154953294895622, time: 11.625
steps: 499975, episodes: 20000, mean episode reward: -6.426832532841338, time: 11.917
